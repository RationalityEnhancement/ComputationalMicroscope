{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "promotional-consolidation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "from analysis_utils import get_data\n",
    "from learning_utils import pickle_load, pickle_save, get_strategy_counts, get_cluster_dict, get_modified_weights, \\\n",
    "                            get_normalized_features, create_dir\n",
    "from planning_strategies import strategy_dict\n",
    "from rl_models import models as rl_models\n",
    "import seaborn as sns\n",
    "from computational_microscope import ComputationalMicroscope\n",
    "from statsmodels.stats.proportion import proportions_ztest, proportions_chisquare\n",
    "from scipy.stats import ttest_ind, pearsonr\n",
    "from IPython.core.display import display, HTML\n",
    "from experiment_utils import Experiment\n",
    "from result_utils import *\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plt.rcParams[\"axes.grid\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-outdoors",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "2. Unique strategies and strategy percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "warming-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pickle_load(\"data/microscope_features.pkl\")\n",
    "exp_pipelines = pickle_load(\"data/exp_pipelines.pkl\")\n",
    "exp_reward_structures = {'v1.0': 'high_increasing', 'F1': 'high_increasing', 'c1.1': 'low_constant', 'T1.1': 'large_increasing'}\n",
    "num_features = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "formed-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pickle_load(\"data/microscope_features.pkl\")\n",
    "\n",
    "decision_systems = pickle_load(\"data/decision_systems.pkl\")\n",
    "feature_systems = pickle_load(\"data/feature_systems.pkl\")\n",
    "decision_system_features = pickle_load(\"data/decision_system_features.pkl\")\n",
    "\n",
    "W_DS = pickle_load(\"data/strategy_decision_weights.pkl\")\n",
    "DS_proportions = pickle_load(\"data/strategy_decision_proportions.pkl\")\n",
    "\n",
    "strategy_weights = pickle_load(\"data/microscope_weights.pkl\")\n",
    "\n",
    "L1_DS = pickle_load(\"data/L1_DS.pkl\")\n",
    "L2_DS = pickle_load(\"data/L2_DS.pkl\")\n",
    "L1_norm_DS = pickle_load(\"data/L1_norm_DS.pkl\")\n",
    "L2_norm_DS = pickle_load(\"data/L2_norm_DS.pkl\")\n",
    "\n",
    "L1_distances = pickle_load(\"data/L1_distances.pkl\")\n",
    "L2_distances = pickle_load(\"data/L2_distances.pkl\")\n",
    "jeffreys_divergence = pickle_load(\"data/jeffreys_divergences.pkl\")\n",
    "jsd = pickle_load(\"data/js_divergences.pkl\")\n",
    "\n",
    "strategy_space = pickle_load(\"data/strategy_space.pkl\")\n",
    "num_strategies = len(strategy_space)\n",
    "strategy_feature_scores = pickle_load(\"data/strategy_feature_scores.pkl\") # Average scores using feature based representation of the strategies\n",
    "strategy_scores = pickle_load(\"data/strategy_scores.pkl\") # Average scores using an algorithmic representation of the strategies\n",
    "\n",
    "clusters = pickle_load(\"data/kl_clusters.pkl\")\n",
    "cluster_map = pickle_load(\"data/kl_cluster_map.pkl\")\n",
    "\n",
    "cluster_scores = pickle_load(\"data/cluster_scores.pkl\")\n",
    "cluster_names = pickle_load(\"data/cluster_names.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coupled-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_E(exp_num, increasing=False, condition='', block=''):\n",
    "    pids = None\n",
    "    if exp_num == \"T1.1\":\n",
    "        block = 'test'\n",
    "    exp_data = get_data(exp_num)\n",
    "    participants_df = exp_data['participants']\n",
    "    if 'pids' in exp_data:\n",
    "        pids = sorted(exp_data['pids']['pids'].tolist())\n",
    "    else:\n",
    "        pids = participants_df['pid'].tolist()\n",
    "    trials_data = exp_data['mouselab-mdp']\n",
    "    participant_conditions = {}\n",
    "    if exp_num in [\"c1.1\", \"c2.1\"]:\n",
    "        trials_data = trials_data[trials_data.block == \"test\"]\n",
    "        if exp_num in \"c2.1\":\n",
    "            conditions = participants_df[['pid', 'variance']]\n",
    "            conditions.set_index('pid', inplace = True)\n",
    "            participant_conditions = conditions.to_dict()['variance']\n",
    "            increasing_pids = [pid for pid in participant_conditions.keys() if participant_conditions[pid] == 2424 and pid in pids]\n",
    "            decreasing_pids = [pid for pid in participant_conditions.keys() if participant_conditions[pid] == 2442 and pid in pids]\n",
    "    if not exp_num == \"c2.1\":\n",
    "            pipeline = exp_pipelines[exp_num]\n",
    "            reward_structure = exp_reward_structures[exp_num]\n",
    "    else:\n",
    "        if increasing:\n",
    "            pipeline = exp_pipelines[\"c2.1_inc\"]\n",
    "            pids = increasing_pids\n",
    "            reward_structure = 'high_increasing'\n",
    "        else:\n",
    "            pipeline = exp_pipelines[\"c2.1_dec\"]\n",
    "            pids = decreasing_pids\n",
    "            reward_structure = 'high_decreasing'\n",
    "\n",
    "    if condition or block:\n",
    "        suffix = block + \"_\" + condition\n",
    "    else:\n",
    "        suffix = \"\"\n",
    "    normalized_features = get_normalized_features(reward_structure)\n",
    "    W = get_modified_weights(strategy_space, strategy_weights)\n",
    "    pipeline = [pipeline[0]]*100\n",
    "    cm = ComputationalMicroscope(pipeline, strategy_space, W, features, normalized_features=normalized_features)\n",
    "    if condition:\n",
    "        if exp_num == \"v1.0\":\n",
    "            E = Experiment(exp_num, cm=cm, pids = pids, feedback=condition)\n",
    "            if block:\n",
    "                E = Experiment(exp_num, cm=cm, pids=pids, feedback=condition, block=block)\n",
    "        else:\n",
    "            E = Experiment(exp_num, cm=cm, pids=pids, condition=condition)\n",
    "    else:\n",
    "        E = Experiment(exp_num, cm=cm, pids=pids)\n",
    "        if block:\n",
    "            E = Experiment(exp_num, cm=cm, block=block, pids=pids)\n",
    "    if block and not exp_num == \"c2.1\":\n",
    "        try:\n",
    "            strategies = pickle_load(f\"results/final_strategy_inferences/{exp_num}_{block}_strategies.pkl\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return E, _, normalized_features, cm\n",
    "    else:\n",
    "        if exp_num == \"c2.1\":\n",
    "            if increasing:\n",
    "                strategies = pickle_load(f\"results/final_strategy_inferences/{exp_num}_inc_strategies.pkl\")\n",
    "                if block:\n",
    "                    strategies = pickle_load(f\"results/final_strategy_inferences/{exp_num}_inc_{block}_strategies.pkl\")\n",
    "                \n",
    "            else:\n",
    "                strategies = pickle_load(f\"results/final_strategy_inferences/{exp_num}_dec_strategies.pkl\")\n",
    "                if block:\n",
    "                    strategies = pickle_load(f\"results/final_strategy_inferences/{exp_num}_dec_{block}_strategies.pkl\")\n",
    "        else:\n",
    "            try:\n",
    "                strategies = pickle_load(f\"results/final_strategy_inferences/{exp_num}_strategies.pkl\")\n",
    "            except:\n",
    "                strategies = None\n",
    "    return E, strategies, normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "descending-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesfactor(f, s):\n",
    "    data = []\n",
    "    for i in f:\n",
    "        data.append([i, \"f\"])\n",
    "    for i in s:\n",
    "        data.append([i, \"s\"])\n",
    "    df = pd.DataFrame(data, columns=[\"count\", \"condition\"])\n",
    "    robjects.globalenv[\"x\"] = df\n",
    "    ttest_output = r('print(t.test(count ~ condition, data = x, var.eq = TRUE, alternative=\"less\"))')\n",
    "    ttest_output = r('print(t.test(count ~ condition, data = x, var.eq = TRUE, alternative=\"greater\"))')\n",
    "    bf = r('print(ttestBF(formula=count ~ condition, data = x, nullInterval = c(0, Inf)))')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-eagle",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "arabic-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_utils import get_standard_error, get_confusion, get_accuracy, get_confusions, get_proportion_confusion, get_proportion_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "another-international",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-wise Accuracy: \n",
      "random\n",
      "Strategy Accuracy:  0.757 ±  0.007\n",
      "Cluster Accuracy:  0.909 ±  0.005 \n",
      "\n",
      "random_switch\n",
      "Strategy Accuracy:  0.88 ±  0.005\n",
      "Cluster Accuracy:  0.962 ±  0.003 \n",
      "\n",
      "gradual\n",
      "Strategy Accuracy:  0.769 ±  0.007\n",
      "Cluster Accuracy:  0.912 ±  0.004 \n",
      "\n",
      "mixed\n",
      "Strategy Accuracy:  0.823 ±  0.006\n",
      "Cluster Accuracy:  0.935 ±  0.004 \n",
      "\n",
      "bernoulli_rssl\n",
      "Strategy Accuracy:  0.755 ±  0.007\n",
      "Cluster Accuracy:  0.904 ±  0.005 \n",
      "\n",
      "Overall Accuracy: \n",
      "Strategy Accuracy:  0.797 ±  0.006\n",
      "Cluster Accuracy:  0.924 ±  0.004 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "strategy_validation_sequences = pickle_load(\"data/strategy_validation_sequences.pkl\")\n",
    "models = [\"random\", \"random_switch\", \"gradual\", \"mixed\", \"bernoulli_rssl\"]\n",
    "distance = \"L2_W\"\n",
    "num_seq = 500\n",
    "TRUE_S = []\n",
    "INFERRED_S = []\n",
    "print(\"Model-wise Accuracy: \")\n",
    "for model in models:\n",
    "    total_accs = []\n",
    "    true_s = []\n",
    "    inferred_s = []\n",
    "    for i in range(num_seq):\n",
    "        acc, data = strategy_validation_sequences[model][distance][i]\n",
    "        strategy_validation_sequences[model][distance].append((acc, data))\n",
    "        true = data[0]['s']\n",
    "        inferred = data[0]['inferred']\n",
    "        total_accs.append(acc)\n",
    "        true_s += true\n",
    "        inferred_s += inferred\n",
    "        TRUE_S += true\n",
    "        INFERRED_S += inferred\n",
    "    num_trials = len(inferred_s)\n",
    "    strategy_confusion, cluster_confusion = get_confusions(true_s, inferred_s, cluster_map)\n",
    "    proportion_strategy_confusion = get_proportion_confusion(strategy_confusion, strategy_space)\n",
    "    proportion_cluster_confusion = get_proportion_confusion(cluster_confusion, range(1, len(clusters)+1))\n",
    "    print(model)\n",
    "    acc = get_accuracy(strategy_confusion)\n",
    "    se = np.round(1.96*get_proportion_se(acc, num_trials), 3)\n",
    "    print(\"Strategy Accuracy: \", acc, \"± \", se)\n",
    "    acc = get_accuracy(cluster_confusion)\n",
    "    se = np.round(1.96*get_proportion_se(acc, num_trials), 3)\n",
    "    print(\"Cluster Accuracy: \", acc, \"± \", se, \"\\n\")\n",
    "    \n",
    "print(\"Overall Accuracy: \")\n",
    "strategy_confusion, cluster_confusion = get_confusions(TRUE_S, INFERRED_S, cluster_map)\n",
    "proportion_strategy_confusion = get_proportion_confusion(strategy_confusion, strategy_space)\n",
    "proportion_cluster_confusion = get_proportion_confusion(cluster_confusion, range(1, len(clusters)+1))\n",
    "\n",
    "acc = get_accuracy(strategy_confusion)\n",
    "se = np.round(1.96*get_proportion_se(acc, num_trials), 3)\n",
    "print(\"Strategy Accuracy: \", acc, \"± \", se)\n",
    "acc = get_accuracy(cluster_confusion)\n",
    "se = np.round(1.96*get_proportion_se(acc, num_trials), 3)\n",
    "print(\"Cluster Accuracy: \", acc, \"± \", se, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-moore",
   "metadata": {},
   "source": [
    "### Empericial analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "molecular-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1, F1_strategies, _ = get_E(\"F1\")\n",
    "v1, v1_strategies, _ = get_E(\"v1.0\")\n",
    "c1, c1_strategies, _ = get_E(\"c1.1\", block='test')\n",
    "c2_inc, c2_inc_strategies, _ = get_E(\"c2.1\", increasing=True, block='test')\n",
    "c2_dec, c2_dec_strategies, _ = get_E(\"c2.1\", increasing=False, block='test')\n",
    "T1, T1_strategies, _ = get_E(\"T1.1\", block='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "advisory-shooting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategies for 103 not found. Skipping adding strategy data\n"
     ]
    }
   ],
   "source": [
    "v1_meta, v1_meta_strategies, _ = get_E(\"v1.0\", condition='meta')\n",
    "v1_meta.infer_strategies(precomputed_strategies=v1_meta_strategies, show_pids=False)\n",
    "v1_action, v1_action_strategies, _ = get_E(\"v1.0\", condition='action')\n",
    "v1_action.infer_strategies(precomputed_strategies=v1_meta_strategies, show_pids=False)\n",
    "v1_nofb, v1_nofb_strategies, _ = get_E(\"v1.0\", condition='none')\n",
    "v1_nofb.infer_strategies(precomputed_strategies=v1_meta_strategies, show_pids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "indie-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "for E in [v1_meta, v1_action, v1_nofb]:\n",
    "    E.init_feature_properties(features, normalized_features, strategy_weights)\n",
    "    E.init_decision_system_properties(decision_systems, W_DS, DS_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-appraisal",
   "metadata": {},
   "source": [
    "### Section 2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faced-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequence_utils import get_acls, summarize_acl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "surprised-competition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1.0\n",
      "Median of average click likelihoods is  0.3340241882664018\n",
      "Median of random average click likelihoods is  0.08737167851715875\n",
      "Mean of average click likelihoods is  0.3734835405256399\n",
      "Mean of random average click likelihoods is  0.09606220613989894\n",
      "c1.1\n",
      "Median of average click likelihoods is  0.00012718500917599507\n",
      "Median of random average click likelihoods is  0.08737167851715875\n",
      "Mean of average click likelihoods is  0.3280536350020796\n",
      "Mean of random average click likelihoods is  0.09224762918365909\n",
      "c2.1_dec\n",
      "Median of average click likelihoods is  0.00023907027731268735\n",
      "Median of random average click likelihoods is  0.08737167851715875\n",
      "Mean of average click likelihoods is  0.25876760863691484\n",
      "Mean of random average click likelihoods is  0.08642677880000138\n",
      "T1.1\n",
      "Median of average click likelihoods is  0.0022667472383766903\n",
      "Median of random average click likelihoods is  0.03287999954443768\n",
      "Mean of average click likelihoods is  0.18675514727058123\n",
      "Mean of random average click likelihoods is  0.03477499826717032\n"
     ]
    }
   ],
   "source": [
    "exps = [\"v1.0\", \"c1.1\", \"c2.1_dec\", \"T1.1\"]\n",
    "ps = [\"high_increasing\", \"low_constant\", \"high_decreasing\", \"large_increasing\"]\n",
    "Es = [v1, c1, c2_dec, T1]\n",
    "Ss = [v1_strategies, c1_strategies, c2_dec_strategies, T1_strategies]\n",
    "for i in range(len(exps)):\n",
    "    print(exps[i])\n",
    "    reward_structure = ps[i]\n",
    "    normalized_features = get_normalized_features(reward_structure)\n",
    "    exp = Es[i]\n",
    "    strategies = Ss[i]\n",
    "    acls, random_acls = get_acls(strategies, exp.pids, exp.planning_data['envs'], exp.planning_data['clicks'], exp_pipelines[exps[i]], features, normalized_features, strategy_weights)\n",
    "    summarize_acl(v1_strategies, acls, random_acls, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-citation",
   "metadata": {},
   "source": [
    "### Section 2.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-excess",
   "metadata": {},
   "source": [
    "### Self-transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "widespread-location",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategies for 103 not found. Skipping adding strategy data\n"
     ]
    }
   ],
   "source": [
    "v_uniform , _, _= get_E(\"v1.0\")\n",
    "uniform_strategies = pickle_load(\"results/uniform_prior_inferences/v1.0_strategies.pkl\")\n",
    "v_uniform.infer_strategies(precomputed_strategies=uniform_strategies, show_pids = False)\n",
    "transition_frequencies = v_uniform.get_transition_frequencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "domestic-smoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 921\n"
     ]
    }
   ],
   "source": [
    "self_transition_counts = []\n",
    "transition_counts = []\n",
    "for tr, k in transition_frequencies.items():\n",
    "    if tr[0] != tr[1]:\n",
    "        transition_counts.append(k)\n",
    "    else:\n",
    "        self_transition_counts.append(k)\n",
    "print(len(self_transition_counts), len(transition_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "upset-bachelor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTwo Sample t-test\n",
      "\n",
      "data:  count by condition\n",
      "t = 7.553, df = 975, p-value = 1\n",
      "alternative hypothesis: true difference in means between group f and group s is less than 0\n",
      "95 percent confidence interval:\n",
      "     -Inf 28.40307\n",
      "sample estimates:\n",
      "mean in group f mean in group s \n",
      "      26.821429        3.501629 \n",
      "\n",
      "\n",
      "\tTwo Sample t-test\n",
      "\n",
      "data:  count by condition\n",
      "t = 7.553, df = 975, p-value = 4.883e-14\n",
      "alternative hypothesis: true difference in means between group f and group s is greater than 0\n",
      "95 percent confidence interval:\n",
      " 18.23653      Inf\n",
      "sample estimates:\n",
      "mean in group f mean in group s \n",
      "      26.821429        3.501629 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: t is large; approximation invoked.\n",
      "\n",
      "R[write to console]: t is large; approximation invoked.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor analysis\n",
      "--------------\n",
      "[1] Alt., r=0.707 0<d<Inf    : 112929441350 ±NA%\n",
      "[2] Alt., r=0.707 !(0<d<Inf) : 0.005514359  ±NA%\n",
      "\n",
      "Against denominator:\n",
      "  Null, mu1-mu2 = 0 \n",
      "---\n",
      "Bayes factor type: BFindepSample, JZS\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(bayesfactor(self_transition_counts, transition_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-complaint",
   "metadata": {},
   "source": [
    "### Section 4.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dietary-print",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0034\n",
      "\n",
      "\n",
      "MCFB mental_effort_avoidance 1.0 0.0001\n",
      "t(108): 2.81, p: 0.006\n",
      "MCFB model-based_metareasoning 248.0 0.0005\n",
      "t(108): -1.11, p: 0.2701\n",
      "MCFB pavlovian 276.0 0.0008\n",
      "t(108): -2.76, p: 0.0068\n",
      "MCFB satisficing_and_stopping 82.0 0.0\n",
      "t(108): -7.45, p: 0.0\n",
      "\n",
      "\n",
      "Action FB model-free_values_and_heuristics 229.0 0.0004\n",
      "t(106): 3.85, p: 0.0002\n",
      "Action FB pavlovian 183.0 0.0005\n",
      "t(106): -3.61, p: 0.0005\n",
      "Action FB satisficing_and_stopping 134.0 0.0001\n",
      "t(106): -3.96, p: 0.0001\n",
      "\n",
      "\n",
      "No FB model-based_metareasoning 206.0 0.0012\n",
      "t(106): -1.66, p: 0.099\n",
      "No FB pavlovian 148.0 0.0\n",
      "t(106): -5.01, p: 0.0\n",
      "No FB satisficing_and_stopping 173.0 0.0002\n",
      "t(106): -3.91, p: 0.0002\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "from learning_utils import sidak_value\n",
    "conditions = [\"MCFB\", \"Action FB\", \"No FB\"]\n",
    "exps = [v1_meta, v1_action, v1_nofb]\n",
    "num_comparisons = 3*5\n",
    "alpha_sidak = np.round(sidak_value(0.05, num_comparisons), 4)\n",
    "print(\"Alpha: \", alpha_sidak)\n",
    "for exp, condition in zip(exps, conditions):\n",
    "    print(\"\\n\")\n",
    "    DSW = exp.get_DSW()\n",
    "    DSW = np.array(DSW)\n",
    "    k = 5\n",
    "    for i in range(DSW.shape[-1]):\n",
    "        x1 = np.mean(DSW[:, :1, i], axis=1)\n",
    "        x2 = np.mean(DSW[:, -10:, i], axis=1)\n",
    "        T, p = wilcoxon(x1, x2)\n",
    "        if p < alpha_sidak:\n",
    "            print(condition, decision_systems[i], T, np.round(p, 4))\n",
    "            t_test(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-calgary",
   "metadata": {},
   "source": [
    "### Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "private-spoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9259259259259258\n",
      "0.8727272727272727\n",
      "2.7037037037037037\n"
     ]
    }
   ],
   "source": [
    "c_nofb_trs, c_nofb_sorted_counts = get_cluster_trajectories(v1_nofb)\n",
    "c_meta_trs, c_meta_sorted_counts = get_cluster_trajectories(v1_meta)\n",
    "c_action_trs, c_action_sorted_counts = get_cluster_trajectories(v1_action)\n",
    "c_nofb_ls = get_lengths(c_nofb_trs)\n",
    "c_meta_ls = get_lengths(c_meta_trs)\n",
    "c_action_ls = get_lengths(c_action_trs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "processed-front",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTwo Sample t-test\n",
      "\n",
      "data:  count by condition\n",
      "t = -2.6463, df = 107, p-value = 0.004683\n",
      "alternative hypothesis: true difference in means between group f and group s is less than 0\n",
      "95 percent confidence interval:\n",
      "       -Inf -0.3928399\n",
      "sample estimates:\n",
      "mean in group f mean in group s \n",
      "      0.8727273       1.9259259 \n",
      "\n",
      "Bayes factor analysis\n",
      "--------------\n",
      "[1] Alt., r=0.707 0<d<Inf    : 0.05914653 ±0.14%\n",
      "[2] Alt., r=0.707 !(0<d<Inf) : 8.772422   ±0%\n",
      "\n",
      "Against denominator:\n",
      "  Null, mu1-mu2 = 0 \n",
      "---\n",
      "Bayes factor type: BFindepSample, JZS\n",
      "\n",
      "\n",
      "\tTwo Sample t-test\n",
      "\n",
      "data:  count by condition\n",
      "t = -3.7278, df = 107, p-value = 0.0001553\n",
      "alternative hypothesis: true difference in means between group f and group s is less than 0\n",
      "95 percent confidence interval:\n",
      "      -Inf -1.016013\n",
      "sample estimates:\n",
      "mean in group f mean in group s \n",
      "      0.8727273       2.7037037 \n",
      "\n",
      "Bayes factor analysis\n",
      "--------------\n",
      "[1] Alt., r=0.707 0<d<Inf    : 0.04556782 ±0.03%\n",
      "[2] Alt., r=0.707 !(0<d<Inf) : 161.3008   ±0%\n",
      "\n",
      "Against denominator:\n",
      "  Null, mu1-mu2 = 0 \n",
      "---\n",
      "Bayes factor type: BFindepSample, JZS\n",
      "\n",
      "\n",
      "\tTwo Sample t-test\n",
      "\n",
      "data:  count by condition\n",
      "t = 1.4593, df = 106, p-value = 0.9263\n",
      "alternative hypothesis: true difference in means between group f and group s is less than 0\n",
      "95 percent confidence interval:\n",
      "    -Inf 1.66216\n",
      "sample estimates:\n",
      "mean in group f mean in group s \n",
      "       2.703704        1.925926 \n",
      "\n",
      "Bayes factor analysis\n",
      "--------------\n",
      "[1] Alt., r=0.707 0<d<Inf    : 0.9635227  ±0%\n",
      "[2] Alt., r=0.707 !(0<d<Inf) : 0.08940762 ±0%\n",
      "\n",
      "Against denominator:\n",
      "  Null, mu1-mu2 = 0 \n",
      "---\n",
      "Bayes factor type: BFindepSample, JZS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MCFB vs No FB\n",
    "bayesfactor(c_meta_ls, c_nofb_ls)\n",
    "\n",
    "# MCFB vs Action FB\n",
    "bayesfactor(c_meta_ls, c_action_ls)\n",
    "\n",
    "# Action vs No FB\n",
    "bayesfactor(c_action_ls, c_nofb_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-heritage",
   "metadata": {},
   "source": [
    "### Strategy frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "excited-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_test(x, N):\n",
    "    data = []\n",
    "    data += [[\"MCFB\", \"Optimal\"]]*x[0]\n",
    "    data += [[\"MCFB\", \"Sub-optimal\"]]*int((N[0]-x[0]))\n",
    "    data += [[\"NFB\", \"Optimal\"]]*x[1]\n",
    "    data += [[\"NFB\", \"Sub-optimal\"]]*int((N[1]-x[1]))\n",
    "    df = pd.DataFrame(data, columns=[\"FB\", \"Strategy\"])\n",
    "    robjects.globalenv[\"x\"] = df\n",
    "    x_vector = robjects.IntVector(x)\n",
    "    N_vector = robjects.IntVector(N)\n",
    "    test = robjects.r('prop.test')\n",
    "    #print(test(x_vector, N_vector, correct=True))\n",
    "    r('print(chisq.test(x$FB, x$Strategy))')\n",
    "    crosstab = r('xtabs(~FB + Strategy, x)')\n",
    "    robjects.globalenv[\"crosstab\"] = crosstab\n",
    "    r('print(contingencyTableBF(crosstab, sampleType = \"indepMulti\", fixedMargin=\"cols\", correct=FALSE))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "preceding-shame",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tPearson's Chi-squared test with Yates' continuity correction\n",
      "\n",
      "data:  x$FB and x$Strategy\n",
      "X-squared = 238.28, df = 1, p-value < 2.2e-16\n",
      "\n",
      "Bayes factor analysis\n",
      "--------------\n",
      "[1] Non-indep. (a=1) : 1.978139e+51 ±0%\n",
      "\n",
      "Against denominator:\n",
      "  Null, independence, a = 1 \n",
      "---\n",
      "Bayes factor type: BFcontingencyTable, independent multinomial\n",
      "\n",
      "15.471441498259233 5.408229959097975e-54\n",
      "\n",
      "\tPearson's Chi-squared test with Yates' continuity correction\n",
      "\n",
      "data:  x$FB and x$Strategy\n",
      "X-squared = 22.061, df = 1, p-value = 2.641e-06\n",
      "\n",
      "Bayes factor analysis\n",
      "--------------\n",
      "[1] Non-indep. (a=1) : 3734.617 ±0%\n",
      "\n",
      "Against denominator:\n",
      "  Null, independence, a = 1 \n",
      "---\n",
      "Bayes factor type: BFcontingencyTable, independent multinomial\n",
      "\n",
      "-4.736391119961749 2.175575365609689e-06\n",
      "\n",
      "\tPearson's Chi-squared test with Yates' continuity correction\n",
      "\n",
      "data:  x$FB and x$Strategy\n",
      "X-squared = 174.26, df = 1, p-value < 2.2e-16\n",
      "\n",
      "Bayes factor analysis\n",
      "--------------\n",
      "[1] Non-indep. (a=1) : 9.374203e+41 ±0%\n",
      "\n",
      "Against denominator:\n",
      "  Null, independence, a = 1 \n",
      "---\n",
      "Bayes factor type: BFcontingencyTable, independent multinomial\n",
      "\n",
      "-13.266420282477773 3.624873563195906e-40\n",
      "\n",
      "\tPearson's Chi-squared test with Yates' continuity correction\n",
      "\n",
      "data:  x$FB and x$Strategy\n",
      "X-squared = 0.89525, df = 1, p-value = 0.3441\n",
      "\n",
      "Bayes factor analysis\n",
      "--------------\n",
      "[1] Non-indep. (a=1) : 0.102242 ±0%\n",
      "\n",
      "Against denominator:\n",
      "  Null, independence, a = 1 \n",
      "---\n",
      "Bayes factor type: BFcontingencyTable, independent multinomial\n",
      "\n",
      "0.9959750487029659 0.31926226859741946\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "conditions = ['Metacognitive FB', 'Action FB', 'No FB']\n",
    "forward_planning_strategies = [3, 10, 82, 5, 36, 37, 54, 79, 22, 23, 32, 33, 53, 64, 65, 69, 70, 80, 28, 34]\n",
    "goal_setting_strategies = [21]\n",
    "forward_freqs = {}\n",
    "goal_setting_freqs = {}\n",
    "total = {}\n",
    "for i, exp in enumerate([v1_meta, v1_action, v1_nofb]):\n",
    "    s_freqs, total_f = exp.get_strategy_frequencies(exp.participant_strategies, trial_wise=True)\n",
    "    forward_freqs[conditions[i]] = np.sum([[s_freqs[t].get(s, 0) for t in s_freqs.keys()] for s in forward_planning_strategies], axis=0)\n",
    "    goal_setting_freqs[conditions[i]] = np.sum([[s_freqs[t].get(s, 0) for t in s_freqs.keys()] for s in goal_setting_strategies], axis=0)\n",
    "    total[conditions[i]] = total_f\n",
    "    \n",
    "z, p = proportions_ztest([np.sum(goal_setting_freqs[conditions[0]]), np.sum(goal_setting_freqs[conditions[2]])], nobs=[np.sum(total[conditions[0]]), np.sum(total[conditions[2]])])\n",
    "prop_test([np.sum(goal_setting_freqs[conditions[0]]), np.sum(goal_setting_freqs[conditions[2]])], [np.sum(total[conditions[0]]), np.sum(total[conditions[2]])])\n",
    "print(z, p)\n",
    "\n",
    "z, p = proportions_ztest([np.sum(goal_setting_freqs[conditions[1]]), np.sum(goal_setting_freqs[conditions[2]])], nobs=[np.sum(total[conditions[1]]), np.sum(total[conditions[2]])])\n",
    "prop_test([np.sum(goal_setting_freqs[conditions[1]]), np.sum(goal_setting_freqs[conditions[2]])], [np.sum(total[conditions[1]]), np.sum(total[conditions[2]])])\n",
    "print(z, p)\n",
    "\n",
    "z, p = proportions_ztest([np.sum(forward_freqs[conditions[0]]), np.sum(forward_freqs[conditions[2]])], nobs=[np.sum(total[conditions[0]]), np.sum(total[conditions[2]])])\n",
    "prop_test([np.sum(forward_freqs[conditions[0]]), np.sum(forward_freqs[conditions[2]])], [np.sum(total[conditions[0]]), np.sum(total[conditions[2]])])\n",
    "print(z, p)\n",
    "\n",
    "z, p = proportions_ztest([np.sum(forward_freqs[conditions[1]]), np.sum(forward_freqs[conditions[2]])], nobs=[np.sum(total[conditions[1]]), np.sum(total[conditions[2]])])\n",
    "prop_test([np.sum(forward_freqs[conditions[1]]), np.sum(forward_freqs[conditions[2]])], [np.sum(total[conditions[1]]), np.sum(total[conditions[2]])])\n",
    "print(z, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-decline",
   "metadata": {},
   "source": [
    "### Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1, v1_strategies, _ = get_E(\"v1.0\")\n",
    "v1.infer_strategies(precomputed_strategies=v1_strategies, show_pids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "best_c = set()\n",
    "for i, exp in enumerate([v1]):\n",
    "    exp.init_strategy_clusters(cluster_map)\n",
    "    props = exp.get_cluster_proportions()\n",
    "    sorted_props = sorted(props.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for p in sorted_props[:k]:\n",
    "        best_c.add(p[0])\n",
    "best_c = sorted(list(best_c))\n",
    "print(best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-hacker",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = [\"Local search\", \"Frugal planning\", \"Myopic planning\", \"Maximizing goal-setting with limited backward planning\", \"Frugal goal-setting strategies\", \"Miscellaneous strategies\"]\n",
    "v1.plot_cluster_proportions(C = best_c, suffix = \"total\", labels=labels, combine_other=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-eugene",
   "metadata": {},
   "source": [
    "### Figure 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1, T1_strategies, _ = get_E(\"T1.1\", block='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strategy_proportions(strategies):\n",
    "    S = []\n",
    "    for s in strategies.values():\n",
    "        if type(s) == list:\n",
    "            S += s\n",
    "    counts = Counter(S)\n",
    "    total_counts = sum(counts.values())\n",
    "    counts = {k: v/total_counts for k, v in counts.items()}\n",
    "    return defaultdict(int, counts)\n",
    "\n",
    "def sort_counts(counts):\n",
    "    sorted_counts = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1.infer_strategies(v1_strategies, show_pids=False)\n",
    "T1.infer_strategies(T1_strategies, show_pids=False)\n",
    "v1.init_strategy_clusters(cluster_map)\n",
    "T1.init_strategy_clusters(cluster_map)\n",
    "v1_proportions = get_strategy_proportions(v1.participant_clusters)\n",
    "T1_proportions = get_strategy_proportions(T1.participant_clusters)\n",
    "v1_cluster_counts = sort_counts(v1_proportions)\n",
    "T1_cluster_counts = sort_counts(T1_proportions)\n",
    "\n",
    "k = 5\n",
    "clusters_set = set()\n",
    "for counts in [v1_cluster_counts, T1_cluster_counts]:\n",
    "    for p in counts[:k]:\n",
    "        clusters_set.add(p[0])\n",
    "print(clusters_set)\n",
    "\n",
    "cluster_list = [12, 5, 7, 9, 10, 13]\n",
    "reward_structures = ['Increasing Variance', 'Transfer task']\n",
    "reward_structure_counts = [v1_proportions, T1_proportions]\n",
    "data = []\n",
    "columns = ['Experiment', 'Strategy Type', 'Proportion (%)']\n",
    "cluster_labels = [\"Immediate outcomes on paths to the best final outcomes\", \"Local Search\", \"Frugal planning\", \"Maximizing goal-setting without backward planning\", \"Frugal goal-setting strategies\", \"Miscellaneous strategies\"]\n",
    "for i in range(len(reward_structures)):\n",
    "    t_prop = 0\n",
    "    for j, cluster in enumerate(cluster_list):\n",
    "        data.append([reward_structures[i], cluster_labels[j], reward_structure_counts[i][cluster]*100])\n",
    "        t_prop += reward_structure_counts[i][cluster]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "plt.figure(figsize=(12, 9))\n",
    "sns.barplot(x = 'Experiment', y='Proportion (%)', hue='Strategy Type', data=df)\n",
    "plt.ylim(top = 60)\n",
    "plt.savefig(\"results/cluster_transfer.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-third",
   "metadata": {},
   "source": [
    "### Figure 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = [\"inc\", \"dec\", \"const\"]\n",
    "ds_validation_sequences = defaultdict(lambda: defaultdict(list))\n",
    "for trend in trends:\n",
    "    for decision_system_index in range(len(decision_systems)):\n",
    "        for run_num in range(num_seq):\n",
    "            ds_validation_sequences[decision_system_index][trend].append(pickle_load(f\"results/decision_system_validation/{decision_system_index}_{trend}_{run_num}.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-salem",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from learning_utils import smoothen\n",
    "trend_labels = [\"Increasing\", \"Decreasing\", \"Constant\"]\n",
    "num_seq = 500\n",
    "num_decision_systems = len(decision_systems)\n",
    "trend_inferred = defaultdict(lambda: defaultdict(list))\n",
    "trend_actual = defaultdict(lambda: defaultdict(list))\n",
    "for trend in trends:\n",
    "    for decision_system_index in range(len(decision_systems)):\n",
    "        for run_num in range(num_seq):\n",
    "            inferred, actual = ds_validation_sequences[decision_system_index][trend][run_num]\n",
    "            ds_validation_sequences[decision_system_index][trend].append((inferred, actual))\n",
    "            inferred_props = [DS_proportions[s-1][decision_system_index] for s in inferred]\n",
    "            actual_props = [DS_proportions[s-1][decision_system_index] for s in actual]\n",
    "            trend_inferred[trend][decision_systems[decision_system_index]].append(inferred_props)\n",
    "            trend_actual[trend][decision_systems[decision_system_index]].append(actual_props)\n",
    "for trend in trends:\n",
    "    for decision_system in decision_systems:\n",
    "        trend_inferred[trend][decision_system] = np.mean(trend_inferred[trend][decision_system], axis = 0)\n",
    "        trend_actual[trend][decision_system] = np.mean(trend_actual[trend][decision_system], axis = 0)\n",
    "        \n",
    "decision_system_labels = [\"Mental effort avoidance\", \"Model-based Metareasoning\", \"Model-free values and heuristics\",\n",
    "                                \"Pavlovian\", \"Satisficing and stopping\"]\n",
    "create_dir(\"results/decision_system_validation_plots\")\n",
    "figure_size = (9, 6)\n",
    "for trend_index, trend in enumerate(trends):\n",
    "    plt.figure(figsize = figure_size)\n",
    "    for index, decision_system in enumerate(decision_systems):\n",
    "        y = smoothen(trend_inferred[trend][decision_system])\n",
    "        plt.plot(range(1, len(y) + 1), y, label = decision_system_labels[index])\n",
    "    plt.xlabel(\"Trial Number\", fontsize=20)\n",
    "    plt.ylabel(\"Relative Influence of the factor\", fontsize=20)\n",
    "    plt.ylim(top = 1.2)\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"results/decision_system_validation_plots/{trend}_inferred.pdf\", bbox_inches='tight')\n",
    "print(figure_size)\n",
    "for trend_index, trend in enumerate(trends):\n",
    "    plt.figure(figsize = figure_size)\n",
    "    for index, decision_system in enumerate(decision_systems):\n",
    "        y = smoothen(trend_actual[trend][decision_system])\n",
    "        plt.plot(range(1, len(y) + 1), y, label = decision_system_labels[index])\n",
    "    plt.xlabel(\"Trial Number\", fontsize=20)\n",
    "    plt.ylabel(\"Relative Influence of the factor\", fontsize=20)\n",
    "    plt.ylim(top = 1.2)\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"results/decision_system_validation_plots/{trend}_actual.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-decline",
   "metadata": {},
   "source": [
    "### Figure 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "forward_planning_strategies = [3, 10, 82, 5, 36, 37, 54, 79, 22, 23, 32, 33, 53, 64, 65, 69, 70, 80, 28, 34]\n",
    "goal_setting_strategies = [21]\n",
    "conditions = ['Metacognitive FB', 'Action FB', 'No FB']\n",
    "markers = [\"*\", \"o\"]\n",
    "forward_labels = [\"Forward planning with Metacognitive FB\", \"Forward planning with Action FB\", \"Forward planning with no FB\"]\n",
    "goal_labels = [\"Near-optimal planning with Metacognitive FB\", \"Near-optimal planning with Action FB\", \"Near-optimal planning with no FB\"]\n",
    "cmap = matplotlib.cm.get_cmap('tab10')\n",
    "colors = [cmap(2), cmap(1), cmap(0)]\n",
    "forward_freqs = {}\n",
    "goal_setting_freqs = {}\n",
    "no_planning_freqs = {}\n",
    "for i, exp in enumerate([v1_meta, v1_action, v1_nofb]):\n",
    "    s_props = exp.get_strategy_proportions(trial_wise=True)\n",
    "    forward_freqs[conditions[i]] = np.sum([[s_props[t].get(s, 0) for t in sorted(s_props.keys())] for s in forward_planning_strategies], axis=0)\n",
    "    goal_setting_freqs[conditions[i]] = np.sum([[s_props[t].get(s, 0) for t in sorted(s_props.keys())] for s in goal_setting_strategies], axis=0)\n",
    "    print(conditions[i], np.mean(forward_freqs[conditions[i]]))\n",
    "    print(conditions[i], np.mean(goal_setting_freqs[conditions[i]]))\n",
    "plt.figure(figsize=(12, 8))\n",
    "for c, condition in enumerate(conditions):\n",
    "    plt.plot(range(1, 31), forward_freqs[condition]*100, marker = markers[1], color = colors[c], label=forward_labels[c], markersize=9)\n",
    "    plt.plot(range(1, 31), goal_setting_freqs[condition]*100, marker = markers[0], color = colors[c], label=goal_labels[c], markersize=9)\n",
    "plt.legend()\n",
    "plt.ylim(top=115)\n",
    "plt.xlabel(\"Trial Number\", fontsize=22)\n",
    "plt.ylabel(\"Proportion (%)\", fontsize=22)\n",
    "plt.savefig(\"results/planning_conditions.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-screw",
   "metadata": {},
   "source": [
    "### Figure 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-reward",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "suffixes = [\"meta\", \"action\", \"none\"]\n",
    "exp_s = [v1_meta_strategies, v1_action_strategies, v1_nofb_strategies]\n",
    "for i, exp in enumerate([v1_meta, v1_action, v1_nofb]):\n",
    "    exp.infer_strategies(precomputed_strategies = exp_s[i], show_pids=False)\n",
    "    exp.init_decision_system_properties(decision_systems, W_DS, DS_proportions)\n",
    "    exp.plot_average_ds(suffix = suffixes[i])\n",
    "    mean_dsw = exp.get_mean_DSW()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-contrary",
   "metadata": {},
   "source": [
    "## Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_participant_count = defaultdict(int)\n",
    "strategy_trial_count = defaultdict(int)\n",
    "strategy_type_participant_count = defaultdict(int)\n",
    "strategy_type_trial_count = defaultdict(int)\n",
    "participant_strategy_trial_count = defaultdict(int)\n",
    "participant_strategy_type_trial_count = defaultdict(int)\n",
    "\n",
    "total_p = 0\n",
    "total_trials = 0\n",
    "strategies = v1_strategies\n",
    "num_trials = 30\n",
    "\n",
    "for k, v in strategies.items():\n",
    "    total_p += 1\n",
    "    total_trials += len(v)\n",
    "    for strategy in range(1, 90):\n",
    "        if strategy in v:\n",
    "            strategy_participant_count[strategy] += 1\n",
    "            participant_strategy_trial_count[strategy] += Counter(v)[strategy]\n",
    "            for s in v:\n",
    "                if s==strategy:\n",
    "                    strategy_trial_count[strategy] += 1\n",
    "\n",
    "for strategy_type in range(1, 14):\n",
    "    for k,v in strategies.items():\n",
    "        strategy_types = [cluster_map[s] for s in v]\n",
    "        if strategy_type in strategy_types:\n",
    "            strategy_type_participant_count[strategy_type] += 1\n",
    "            participant_strategy_type_trial_count[strategy_type] += Counter(strategy_types)[strategy_type]\n",
    "        for st in strategy_types:\n",
    "            if st == strategy_type:\n",
    "                strategy_type_trial_count[strategy_type] += 1\n",
    "\n",
    "participant_strategy_trial_count = {k: np.round(v/(strategy_participant_count[k]*num_trials), 3) for k,v in participant_strategy_trial_count.items()}\n",
    "participant_strategy_type_trial_count = {k: np.round(v/(strategy_type_participant_count[k]*num_trials), 3) for k,v in participant_strategy_type_trial_count.items()}\n",
    "\n",
    "strategy_participant_count = {k: np.round(v/total_p, 3) for k,v in strategy_participant_count.items()}\n",
    "strategy_type_participant_count = {k: np.round(v/total_p, 3) for k,v in strategy_type_participant_count.items()}\n",
    "\n",
    "strategy_trial_count = {k: np.round(v/total_trials, 3) for k,v in strategy_trial_count.items()}\n",
    "strategy_type_trial_count = {k: np.round(v/total_trials, 3) for k,v in strategy_type_trial_count.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for strategy_type, tc in sorted(strategy_type_trial_count.items(), key=operator.itemgetter(1), reverse=True)[:6]:\n",
    "    print(cluster_names[strategy_type], tc, strategy_type_participant_count[strategy_type], participant_strategy_type_trial_count[strategy_type])\n",
    "    for strategy, v in sorted(strategy_trial_count.items(), key=operator.itemgetter(1), reverse=True)[:10]:\n",
    "        if cluster_map[strategy] == strategy_type:\n",
    "            print(strategy, v, strategy_participant_count[strategy], participant_strategy_trial_count[strategy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-berry",
   "metadata": {},
   "source": [
    "## Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "nofb_trs, nofb_sorted_counts = get_trajectories(v1_nofb)\n",
    "c_nofb_trs, c_nofb_sorted_counts = get_cluster_trajectories(v1_nofb)\n",
    "meta_trs, meta_sorted_counts = get_trajectories(v1_meta)\n",
    "c_meta_trs, c_meta_sorted_counts = get_cluster_trajectories(v1_meta)\n",
    "action_trs, action_sorted_counts = get_trajectories(v1_action)\n",
    "c_action_trs, c_action_sorted_counts = get_cluster_trajectories(v1_action)\n",
    "\n",
    "def print_info(props):\n",
    "    for p in props[:5]:\n",
    "        print(tuple(cluster_names[st] for st in p[0]), p[1])\n",
    "\n",
    "print(\"No FB\")\n",
    "props = print_props(c_nofb_sorted_counts, p=False)\n",
    "print_info(props)\n",
    "print(\"Meta FB\")\n",
    "props = print_props(c_meta_sorted_counts, p=False)\n",
    "print_info(props)\n",
    "print(\"Action FB\")\n",
    "props = print_props(c_action_sorted_counts, p=False)\n",
    "print_info(props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-demographic",
   "metadata": {},
   "source": [
    "## Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = 100000\n",
    "strategy_scores_dict = defaultdict(lambda: defaultdict())\n",
    "strategy_mean_scores_dict = defaultdict(lambda: defaultdict())\n",
    "for exp_num in [\"v1.0\", \"c1.1\", \"T1.1\", \"c2.1_dec\"]:\n",
    "    for strategy_num in range(89):\n",
    "        scores, _ = pickle_load(f\"results/strategy_scores_non_optimal/{exp_num}_{strategy_num}.pkl\")\n",
    "        strategy_mean_scores_dict[exp_num][strategy_num+1] = np.mean(scores)\n",
    "        strategy_scores_dict[exp_num][strategy_num + 1] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_test, v1_test_strategies, _ = get_E(\"v1.0\", block=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k(counts, k=4):\n",
    "    S = {c[0] for c in counts[:k]}\n",
    "    return S\n",
    "    \n",
    "def print_strategy_scores(Sf, exp_num):\n",
    "    sorted_freqs = sorted(Sf.items(), key=lambda x:x[1], reverse=True)\n",
    "    max_score = max([strategy_mean_scores_dict[exp_num][s[0]] for s in sorted_freqs])\n",
    "    min_score = min([strategy_mean_scores_dict[exp_num][s[0]] for s in sorted_freqs])\n",
    "    for p in sorted_freqs:\n",
    "        if p[1] >= 0.0295:\n",
    "            k = strategy_mean_scores_dict[exp_num][p[0]]\n",
    "            max_min_norm = np.round((k-min_score)/(max_score-min_score), 2)\n",
    "            print(f\"Strategy: {p[0]}, Strategy Freq: {np.round(p[1], 3)}, Score: {max_min_norm}\")\n",
    "        \n",
    "c1_counts = get_strategy_proportions(c1_strategies)\n",
    "c2_inc_counts = get_strategy_proportions(c2_inc_strategies)\n",
    "c2_dec_counts = get_strategy_proportions(c2_dec_strategies)\n",
    "transfer_counts = get_strategy_proportions(T1_strategies)\n",
    "v1_counts = get_strategy_proportions(v1_test_strategies)\n",
    "\n",
    "print(\"Increasing variance - 3 steps\")\n",
    "print_strategy_scores(v1_counts, \"v1.0\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Increasing variance - 5 steps\")\n",
    "print_strategy_scores(transfer_counts, \"T1.1\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Decreasing variance\")\n",
    "print_strategy_scores(c2_dec_counts, \"c2.1_dec\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Constant variance\")\n",
    "print_strategy_scores(c1_counts, \"c1.1\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-bhutan",
   "metadata": {},
   "source": [
    "## Table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_type_scores = defaultdict(lambda: defaultdict(list))\n",
    "strategy_type_mean_scores = defaultdict(lambda: defaultdict(list))\n",
    "exp_nums = [\"v1.0\", \"c1.1\", \"T1.1\", \"c2.1_dec\"]\n",
    "for strategy in strategy_space:\n",
    "    for exp_num in exp_nums:\n",
    "        strategy_type_scores[exp_num][cluster_map[strategy]] += (strategy_scores_dict[exp_num][strategy])\n",
    "        strategy_type_mean_scores[exp_num][cluster_map[strategy]].append(strategy_mean_scores_dict[exp_num][strategy])\n",
    "\n",
    "for exp_num in exp_nums:\n",
    "    for k in strategy_type_scores[exp_num].keys():\n",
    "        strategy_type_mean_scores[exp_num][k] = np.mean(strategy_type_mean_scores[exp_num][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_strategy_types(S):\n",
    "    return [cluster_map[s] for s in S]\n",
    "\n",
    "def print_scores(Sf, exp_num):\n",
    "    sorted_freqs = sorted(Sf.items(), key=lambda x:x[1], reverse=True)\n",
    "    max_score = max([strategy_type_mean_scores[exp_num][s[0]] for s in sorted_freqs])\n",
    "    min_score = min([strategy_type_mean_scores[exp_num][s[0]] for s in sorted_freqs])\n",
    "    print(max_score, min_score)\n",
    "    for p in sorted_freqs:\n",
    "        if p[1] >= 0.0295:\n",
    "            k = strategy_type_mean_scores[exp_num][p[0]]\n",
    "            max_min_norm = np.round((k-min_score)/(max_score-min_score), 2)\n",
    "            print(f\"Strategy Type: {cluster_names[p[0]]}, Strategy Freq: {np.round(p[1], 3)}, {strategy_type_mean_scores[exp_num][p[0]]}, Score: {max_min_norm}\")\n",
    "        \n",
    "exp_nums = [\"v1.0\", \"T1.1\", \"c2.1_dec\", \"c1.1\"]\n",
    "\n",
    "for exp_num in exp_nums:\n",
    "    for k in strategy_type_scores[exp_num].keys():\n",
    "        strategy_type_mean_scores[exp_num][k] = np.mean(strategy_type_mean_scores[exp_num][k])\n",
    "        \n",
    "c1_strategy_types = get_strategy_proportions({k: make_strategy_types(v) for k,v in c1_strategies.items()})\n",
    "c2_inc_strategy_types = get_strategy_proportions({k: make_strategy_types(v) for k,v in c2_inc_strategies.items()})\n",
    "c2_dec_strategy_types = get_strategy_proportions({k: make_strategy_types(v) for k,v in c2_dec_strategies.items()})\n",
    "transfer_strategy_types = get_strategy_proportions({k: make_strategy_types(v) for k, v in T1_strategies.items()})\n",
    "v1_strategy_types = get_strategy_proportions({k: make_strategy_types(v) for k, v in v1_test_strategies.items()})\n",
    "\n",
    "print(\"Increasing variance - 3 steps\")\n",
    "print_scores(v1_strategy_types, \"v1.0\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Increasing variance - 5 steps\")\n",
    "print_scores(transfer_strategy_types, \"T1.1\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Decreasing variance\")\n",
    "print_scores(c2_dec_strategy_types, \"c2.1_dec\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Constant variance\")\n",
    "print_scores(c1_strategy_types, \"c1.1\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-intent",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_si_map = pickle_load(\"data/strategy_si_map.pkl\")\n",
    "si_strategy_map = pickle_load(\"data/si_strategy_map.pkl\")\n",
    "si_strategy_space = [si_strategy_map[s] for s in range(1, 80)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-timer",
   "metadata": {},
   "source": [
    "## Appendix tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_table(exp):\n",
    "    data = []\n",
    "    xs = []\n",
    "    for strategy in si_strategy_space:\n",
    "        path = f\"results/strategy_likelihoods/{strategy}\"\n",
    "        if exp == \"transfer\":\n",
    "            path += \"_transfer\"\n",
    "        L = pickle_load(path+\".pkl\")\n",
    "        sorted_L = np.sort(L)[:, ::-1]\n",
    "        median_best = np.median(np.exp(sorted_L[:, 0] - sorted_L[:,1]))\n",
    "        max_L = np.max(L, axis=1)\n",
    "        diff_L = L - max_L[:, None]\n",
    "        ratio_L = np.exp(diff_L)\n",
    "        mean_ratio_L = np.mean(ratio_L, axis=0)\n",
    "        mean_ratio_L = [np.round(l, 3) for l in mean_ratio_L]\n",
    "        data.append([strategy_si_map[strategy]] + [median_best] + sorted(mean_ratio_L)[-10:][::-1])\n",
    "        x = sorted(mean_ratio_L)[-10:][::-1]\n",
    "        if x[1] != 0:\n",
    "            xs.append(x[0]/x[1])\n",
    "    df = pd.DataFrame(data, columns = [\"Strategy\", \"LR\"] + list(range(1, 11)))\n",
    "    df = df.set_index(\"Strategy\")\n",
    "    pd.reset_option('display.float_format')\n",
    "    print(np.median(xs))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_latex = gen_table(\"v1.0\")\n",
    "transfer_latex = gen_table(\"transfer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('cogtut': conda)",
   "language": "python",
   "name": "python37364bitcogtutconda3e89249cb8f1438ca66244f989548773"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
